{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d12e8e88-6ac6-4f18-ac80-61a7230b1528",
   "metadata": {},
   "source": [
    "# Logistic Regression (Wisconsin Diagnostic Breast Cancer)\n",
    "Logistic regression minimizes the **negative log-likelihood**, also called the **binary cross-entropy loss**. For binary classification:\n",
    "\n",
    "$$\n",
    "\\min_{\\theta} \\ \\mathcal{L}(\\theta) = - \\sum_{i=1}^{n} \\left[ y_i \\log \\sigma(x_i^\\top \\theta) + (1 - y_i) \\log (1 - \\sigma(x_i^\\top \\theta)) \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $x_i \\in \\mathbb{R}^d$ is the input vector for example $i$\n",
    "* $y_i \\in \\{0, 1\\}$ is the true label\n",
    "* $\\theta \\in \\mathbb{R}^d$ are the weights\n",
    "* $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ is the sigmoid function\n",
    "\n",
    "It is recommended to absorb the bias into theta, by appending 1 to each feature and an extra parameter for the bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3782fda-ed6d-4e56-8aff-c9e19a1f39b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335d5f67-3250-4d5c-9e61-c2ed4bcf3e90",
   "metadata": {},
   "source": [
    "# Dataset overview:\n",
    "\n",
    "Relevant to our purposes is the following information from `data/wdbc.names`:\n",
    "\n",
    "```\n",
    "5. Number of instances: 569 \n",
    "\n",
    "6. Number of attributes: 32 (ID, diagnosis, 30 real-valued input features)\n",
    "\n",
    "7. Attribute information\n",
    "\n",
    "1) ID number\n",
    "2) Diagnosis (M = malignant, B = benign)\n",
    "3-32)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "\ta) radius (mean of distances from center to points on the perimeter)\n",
    "\tb) texture (standard deviation of gray-scale values)\n",
    "\tc) perimeter\n",
    "\td) area\n",
    "\te) smoothness (local variation in radius lengths)\n",
    "\tf) compactness (perimeter^2 / area - 1.0)\n",
    "\tg) concavity (severity of concave portions of the contour)\n",
    "\th) concave points (number of concave portions of the contour)\n",
    "\ti) symmetry \n",
    "\tj) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "Several of the papers listed above contain detailed descriptions of\n",
    "how these features are computed. \n",
    "\n",
    "The mean, standard error, and \"worst\" or largest (mean of the three\n",
    "largest values) of these features were computed for each image,\n",
    "resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
    "13 is Radius SE, field 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "8. Missing attribute values: none\n",
    "\n",
    "9. Class distribution: 357 benign, 212 malignant\n",
    "```\n",
    "\n",
    "The following column list converts this information into a descriptive pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0238826a-00a5-48a8-8d77-30ef14d2af2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_number</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>radius_se</th>\n",
       "      <th>radius_max</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>texture_se</th>\n",
       "      <th>texture_max</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>perimeter_se</th>\n",
       "      <th>...</th>\n",
       "      <th>concavity_max</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>concave_points_se</th>\n",
       "      <th>concave_points_max</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>symmetry_se</th>\n",
       "      <th>symmetry_max</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>fractal_dimension_se</th>\n",
       "      <th>fractal_dimension_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_number diagnosis  radius_mean  radius_se  radius_max  texture_mean  \\\n",
       "0       842302         M        17.99      10.38      122.80        1001.0   \n",
       "1       842517         M        20.57      17.77      132.90        1326.0   \n",
       "2     84300903         M        19.69      21.25      130.00        1203.0   \n",
       "3     84348301         M        11.42      20.38       77.58         386.1   \n",
       "4     84358402         M        20.29      14.34      135.10        1297.0   \n",
       "..         ...       ...          ...        ...         ...           ...   \n",
       "564     926424         M        21.56      22.39      142.00        1479.0   \n",
       "565     926682         M        20.13      28.25      131.20        1261.0   \n",
       "566     926954         M        16.60      28.08      108.30         858.1   \n",
       "567     927241         M        20.60      29.33      140.10        1265.0   \n",
       "568      92751         B         7.76      24.54       47.92         181.0   \n",
       "\n",
       "     texture_se  texture_max  perimeter_mean  perimeter_se  ...  \\\n",
       "0       0.11840      0.27760         0.30010       0.14710  ...   \n",
       "1       0.08474      0.07864         0.08690       0.07017  ...   \n",
       "2       0.10960      0.15990         0.19740       0.12790  ...   \n",
       "3       0.14250      0.28390         0.24140       0.10520  ...   \n",
       "4       0.10030      0.13280         0.19800       0.10430  ...   \n",
       "..          ...          ...             ...           ...  ...   \n",
       "564     0.11100      0.11590         0.24390       0.13890  ...   \n",
       "565     0.09780      0.10340         0.14400       0.09791  ...   \n",
       "566     0.08455      0.10230         0.09251       0.05302  ...   \n",
       "567     0.11780      0.27700         0.35140       0.15200  ...   \n",
       "568     0.05263      0.04362         0.00000       0.00000  ...   \n",
       "\n",
       "     concavity_max  concave_points_mean  concave_points_se  \\\n",
       "0           25.380                17.33             184.60   \n",
       "1           24.990                23.41             158.80   \n",
       "2           23.570                25.53             152.50   \n",
       "3           14.910                26.50              98.87   \n",
       "4           22.540                16.67             152.20   \n",
       "..             ...                  ...                ...   \n",
       "564         25.450                26.40             166.10   \n",
       "565         23.690                38.25             155.00   \n",
       "566         18.980                34.12             126.70   \n",
       "567         25.740                39.42             184.60   \n",
       "568          9.456                30.37              59.16   \n",
       "\n",
       "     concave_points_max  symmetry_mean  symmetry_se  symmetry_max  \\\n",
       "0                2019.0        0.16220      0.66560        0.7119   \n",
       "1                1956.0        0.12380      0.18660        0.2416   \n",
       "2                1709.0        0.14440      0.42450        0.4504   \n",
       "3                 567.7        0.20980      0.86630        0.6869   \n",
       "4                1575.0        0.13740      0.20500        0.4000   \n",
       "..                  ...            ...          ...           ...   \n",
       "564              2027.0        0.14100      0.21130        0.4107   \n",
       "565              1731.0        0.11660      0.19220        0.3215   \n",
       "566              1124.0        0.11390      0.30940        0.3403   \n",
       "567              1821.0        0.16500      0.86810        0.9387   \n",
       "568               268.6        0.08996      0.06444        0.0000   \n",
       "\n",
       "     fractal_dimension_mean  fractal_dimension_se  fractal_dimension_max  \n",
       "0                    0.2654                0.4601                0.11890  \n",
       "1                    0.1860                0.2750                0.08902  \n",
       "2                    0.2430                0.3613                0.08758  \n",
       "3                    0.2575                0.6638                0.17300  \n",
       "4                    0.1625                0.2364                0.07678  \n",
       "..                      ...                   ...                    ...  \n",
       "564                  0.2216                0.2060                0.07115  \n",
       "565                  0.1628                0.2572                0.06637  \n",
       "566                  0.1418                0.2218                0.07820  \n",
       "567                  0.2650                0.4087                0.12400  \n",
       "568                  0.0000                0.2871                0.07039  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "df = pd.read_csv('data/wdbc.data', header=None)\n",
    "features = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', 'concavity', 'concave_points', 'symmetry', 'fractal_dimension']\n",
    "measurement = ['mean', 'se', 'max']\n",
    "df.columns = ['id_number', 'diagnosis'] + list(map(lambda t: '_'.join(t), itertools.product(features, measurement)))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16afe970-abf9-43b5-90cb-6e9fac0a850b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_df(df):\n",
    "    return df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "def split_df(df, frac):\n",
    "    idx = int(len(df) * frac)\n",
    "    return df[:idx], df[idx:]\n",
    "\n",
    "def preprocess_df(df):\n",
    "    labels = (df['diagnosis'] == 'M')\n",
    "    features = df.drop(['id_number', 'diagnosis'], axis=1)\n",
    "    return features, labels\n",
    "\n",
    "train, test = split_df(shuffle_df(df), 0.8)\n",
    "feats, labels = preprocess_df(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c884dfc-4910-4e4c-b5fd-cc4fb8833613",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, labels = preprocess_df(train)\n",
    "X_train, y_train = jnp.array(feats.values), jnp.array(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04f321f2-7c35-47a3-81ae-cce2b0f44d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params(X_train):\n",
    "    key = jax.random.key(42)\n",
    "\n",
    "    mu = jnp.mean(X_train, axis=0)\n",
    "    sigma = jnp.std(X_train, axis=0)\n",
    "    \n",
    "    key, subkey = jax.random.split(key)\n",
    "    theta = jax.random.normal(subkey, (X_train.shape[1]+1,))\n",
    "    del subkey\n",
    "    \n",
    "    params = (mu, sigma, theta)\n",
    "    \n",
    "    return params\n",
    "params = create_params(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "07e841ba-2107-47f2-9ec6-42f145ab1288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd(params, X):\n",
    "    mu, sigma, theta = params\n",
    "    X_norm = (X - mu) / sigma\n",
    "    X_norm = jnp.hstack([X_norm, jnp.ones((X.shape[0], 1))])\n",
    "    logits = X_norm @ theta\n",
    "    return logits\n",
    "\n",
    "# fwd(theta, X_train)\n",
    "\n",
    "def predict(params, X):\n",
    "    return jax.nn.sigmoid(fwd(params, X))\n",
    "\n",
    "def loss(theta, mu, sigma, X, y):\n",
    "    params = mu, sigma, theta\n",
    "    y = 2*y - 1 # remap labels to -1, +1\n",
    "    logits = fwd(params, X)\n",
    "    loss = jnp.mean(jnp.logaddexp(0, -y * logits))  # y in {-1, 1}, @TODO: unpack; this line is pure chatgpt\n",
    "    return loss + 1e-4 * jnp.sum(theta ** 2)\n",
    "\n",
    "# loss(params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "eb33780d-25ea-4bee-9180-f107f4eb18b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 1.7558537721633911\n",
      "step 100000, loss: 0.09227238595485687\n",
      "step 200000, loss: 0.07621347159147263\n",
      "step 300000, loss: 0.0691460371017456\n",
      "step 400000, loss: 0.06489294767379761\n",
      "step 500000, loss: 0.061977189034223557\n",
      "step 600000, loss: 0.0598461739718914\n",
      "step 700000, loss: 0.058205634355545044\n",
      "step 800000, loss: 0.056896310299634933\n",
      "step 900000, loss: 0.055809326469898224\n",
      "step 1000000, loss: 0.05489137023687363\n",
      "step 1100000, loss: 0.05408978834748268\n",
      "step 1200000, loss: 0.0533839613199234\n",
      "step 1300000, loss: 0.052760522812604904\n",
      "step 1400000, loss: 0.0522017665207386\n",
      "step 1500000, loss: 0.05171068385243416\n",
      "step 1600000, loss: 0.05127420276403427\n",
      "step 1700000, loss: 0.05086661875247955\n",
      "step 1800000, loss: 0.05048423260450363\n",
      "step 1900000, loss: 0.05012185499072075\n",
      "step 2000000, loss: 0.04978455230593681\n",
      "step 2100000, loss: 0.04946058616042137\n",
      "step 2200000, loss: 0.04915091022849083\n",
      "step 2300000, loss: 0.04885657876729965\n",
      "step 2400000, loss: 0.04857207089662552\n",
      "step 2500000, loss: 0.04829733073711395\n",
      "step 2600000, loss: 0.048030342906713486\n",
      "step 2700000, loss: 0.047772396355867386\n",
      "step 2800000, loss: 0.047519929707050323\n",
      "step 2900000, loss: 0.047286372631788254\n",
      "step 3000000, loss: 0.04706324264407158\n",
      "step 3100000, loss: 0.04684693366289139\n",
      "step 3200000, loss: 0.04662832245230675\n",
      "step 3300000, loss: 0.046406060457229614\n",
      "step 3400000, loss: 0.04618733748793602\n",
      "step 3500000, loss: 0.0459725558757782\n",
      "step 3600000, loss: 0.0457732267677784\n",
      "step 3700000, loss: 0.04558658227324486\n",
      "step 3800000, loss: 0.045414917171001434\n",
      "step 3900000, loss: 0.045249491930007935\n",
      "step 4000000, loss: 0.0450926348567009\n",
      "step 4100000, loss: 0.04494480788707733\n",
      "step 4200000, loss: 0.04480393975973129\n",
      "step 4300000, loss: 0.04466577246785164\n",
      "step 4400000, loss: 0.044532958418130875\n",
      "step 4500000, loss: 0.044404152780771255\n",
      "step 4600000, loss: 0.04427666962146759\n",
      "step 4700000, loss: 0.044151388108730316\n",
      "step 4800000, loss: 0.044031888246536255\n",
      "step 4900000, loss: 0.04391240328550339\n",
      "step 5000000, loss: 0.0437915176153183\n",
      "step 5100000, loss: 0.043669309467077255\n",
      "step 5200000, loss: 0.04354763776063919\n",
      "step 5300000, loss: 0.043427154421806335\n",
      "step 5400000, loss: 0.04330785572528839\n",
      "step 5500000, loss: 0.04319083318114281\n",
      "step 5600000, loss: 0.043075405061244965\n",
      "step 5700000, loss: 0.042961105704307556\n",
      "step 5800000, loss: 0.042848315089941025\n",
      "step 5900000, loss: 0.04273710772395134\n",
      "step 6000000, loss: 0.04262810945510864\n",
      "step 6100000, loss: 0.042524248361587524\n",
      "step 6200000, loss: 0.04242269694805145\n",
      "step 6300000, loss: 0.04232258349657059\n",
      "step 6400000, loss: 0.042223669588565826\n",
      "step 6500000, loss: 0.04212610796093941\n",
      "step 6600000, loss: 0.042029544711112976\n",
      "step 6700000, loss: 0.04193459078669548\n",
      "step 6800000, loss: 0.04184045270085335\n",
      "step 6900000, loss: 0.041747212409973145\n",
      "step 7000000, loss: 0.04165519028902054\n",
      "step 7100000, loss: 0.041564032435417175\n",
      "step 7200000, loss: 0.04147927090525627\n",
      "step 7300000, loss: 0.04140009358525276\n",
      "step 7400000, loss: 0.04132242128252983\n",
      "step 7500000, loss: 0.04124760255217552\n",
      "step 7600000, loss: 0.0411737896502018\n",
      "step 7700000, loss: 0.04110054671764374\n",
      "step 7800000, loss: 0.04102785885334015\n",
      "step 7900000, loss: 0.04095612093806267\n",
      "step 8000000, loss: 0.040887847542762756\n",
      "step 8100000, loss: 0.04082046076655388\n",
      "step 8200000, loss: 0.04075360298156738\n",
      "step 8300000, loss: 0.040687303990125656\n",
      "step 8400000, loss: 0.04062153771519661\n",
      "step 8500000, loss: 0.04055630788207054\n",
      "step 8600000, loss: 0.04049377888441086\n",
      "step 8700000, loss: 0.040433622896671295\n",
      "step 8800000, loss: 0.04037390649318695\n",
      "step 8900000, loss: 0.04031467065215111\n",
      "step 9000000, loss: 0.04025610163807869\n",
      "step 9100000, loss: 0.04019796848297119\n",
      "step 9200000, loss: 0.04013989120721817\n",
      "step 9300000, loss: 0.04008215665817261\n",
      "step 9400000, loss: 0.04002479836344719\n",
      "step 9500000, loss: 0.03996782749891281\n",
      "step 9600000, loss: 0.03991127759218216\n",
      "step 9700000, loss: 0.03985515609383583\n",
      "step 9800000, loss: 0.03979945927858353\n",
      "step 9900000, loss: 0.039744190871715546\n"
     ]
    }
   ],
   "source": [
    "grad_loss = jax.jit(jax.grad(loss))\n",
    "\n",
    "@jax.jit\n",
    "def train(params):\n",
    "    mu, sigma, theta = params\n",
    "    lr = 0.0001\n",
    "\n",
    "    def body(i, theta):\n",
    "        theta -= lr * grad_loss(theta, mu, sigma, X_train, y_train)\n",
    "\n",
    "        def do_print(_):\n",
    "            jax.debug.print(\"step {i}, loss: {l}\", i=i, l=loss(theta, mu, sigma, X_train, y_train))\n",
    "            return None\n",
    "\n",
    "        _ = jax.lax.cond(i % 100000 == 0, do_print, lambda _: None, operand=None)\n",
    "        return theta\n",
    "\n",
    "    theta = jax.lax.fori_loop(0, 10000000, body, theta)\n",
    "    return theta\n",
    "\n",
    "theta = train(create_params(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "07c04d8a-a203-45f1-a705-b7cf6e8bb6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.03968935, dtype=float32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(theta, mu, sigma, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a603893-0529-4c79-ad6c-7a9cca4cd105",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats, labels = preprocess_df(test)\n",
    "X_test, y_test = jnp.array(feats.values), jnp.array(labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dbf9160d-b81d-44d9-a2d1-df8464118ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([9.99999881e-01, 9.99999881e-01, 3.51411509e-05, 9.99995708e-01,\n",
       "       1.00000000e+00, 5.97806029e-05, 3.86891770e-07, 3.05701105e-05,\n",
       "       1.00000000e+00, 3.50525681e-07, 9.99999404e-01, 1.00000000e+00,\n",
       "       9.99983668e-01, 8.49106610e-02, 5.14403544e-02, 4.29154234e-03,\n",
       "       9.99707639e-01, 5.18027155e-05, 5.42503141e-04, 9.99883533e-01,\n",
       "       1.00000000e+00, 9.92534518e-01, 9.99998212e-01, 4.54434864e-02,\n",
       "       9.99103963e-01, 9.47632536e-04, 1.40104760e-07, 4.80581395e-04,\n",
       "       1.49442954e-03, 8.56768456e-04, 1.37061816e-05, 1.12894350e-06,\n",
       "       1.00000000e+00, 1.00000000e+00, 9.99176800e-01, 1.00000000e+00,\n",
       "       1.22511283e-05, 2.98149139e-02, 2.36257416e-04, 2.01730698e-01,\n",
       "       1.00000000e+00, 5.28299093e-01, 9.98454452e-01, 4.25819871e-06,\n",
       "       9.21360606e-06, 1.01508795e-05, 3.20190354e-03, 1.80602800e-02,\n",
       "       9.99873519e-01, 1.00000000e+00, 9.92593467e-01, 7.68189636e-07,\n",
       "       2.57860538e-05, 2.64904816e-02, 1.36944860e-01, 3.06835791e-05,\n",
       "       1.00000000e+00, 9.99893308e-01, 9.99999881e-01, 9.99999881e-01,\n",
       "       8.44531241e-05, 6.04116265e-03, 6.75924361e-01, 9.99981523e-01,\n",
       "       2.55313739e-02, 8.37106723e-04, 4.48191044e-04, 1.00000000e+00,\n",
       "       6.39488637e-01, 1.00000000e+00, 1.44618717e-08, 9.56247050e-07,\n",
       "       4.00155842e-01, 5.40280837e-07, 1.21039666e-05, 1.26924090e-06,\n",
       "       8.60486864e-08, 1.00000000e+00, 2.14378517e-02, 2.99410126e-03,\n",
       "       1.19440505e-04, 1.03212439e-03, 5.86661770e-07, 1.96116438e-04,\n",
       "       1.33797607e-06, 1.09578550e-05, 1.84602402e-06, 1.00000000e+00,\n",
       "       5.64010634e-07, 4.75645798e-08, 1.20100376e-05, 1.68815795e-02,\n",
       "       7.84229783e-08, 1.08811483e-02, 9.42823172e-01, 5.52583516e-01,\n",
       "       4.20043409e-01, 1.00000000e+00, 8.46171417e-07, 1.83449229e-05,\n",
       "       8.12663198e-01, 9.99965906e-01, 1.00000000e+00, 8.94275086e-04,\n",
       "       9.93899465e-01, 9.99206603e-01, 6.90892488e-02, 1.00000000e+00,\n",
       "       8.87629431e-05, 7.91936725e-11, 8.59405026e-02, 9.85956376e-07,\n",
       "       9.97404635e-01, 5.27750468e-04], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [mu, sigma, theta]\n",
    "y_pred = predict(params, X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9995e5fc-3652-4534-be74-933f5467318e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.12718126, dtype=float32)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(theta, mu, sigma, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b6db46c3-8a90-4ee9-bbdf-3a85b332b76e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.94736844, dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def accuracy(y_pred, y_act):\n",
    "    return jnp.sum(1 - jnp.round(jnp.abs(y_pred - y_act))) / len(y_act)\n",
    "\n",
    "accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "51e065e7-a435-4b9f-b1f6-c35d726e413c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: 0.03968934714794159\n",
      "step 100000, loss: 0.039634015411138535\n",
      "step 200000, loss: 0.03957916051149368\n",
      "step 300000, loss: 0.039524853229522705\n",
      "step 400000, loss: 0.03947202116250992\n",
      "step 500000, loss: 0.0394204743206501\n",
      "step 600000, loss: 0.03936953470110893\n",
      "step 700000, loss: 0.0393189862370491\n",
      "step 800000, loss: 0.03926884010434151\n",
      "step 900000, loss: 0.03922383114695549\n",
      "step 1000000, loss: 0.039185721427202225\n",
      "step 1100000, loss: 0.039147742092609406\n",
      "step 1200000, loss: 0.03911023586988449\n",
      "step 1300000, loss: 0.03907322883605957\n",
      "step 1400000, loss: 0.03903794661164284\n",
      "step 1500000, loss: 0.0390034094452858\n",
      "step 1600000, loss: 0.03896983340382576\n",
      "step 1700000, loss: 0.03893661126494408\n",
      "step 1800000, loss: 0.03890376165509224\n",
      "step 1900000, loss: 0.03887614607810974\n",
      "step 2000000, loss: 0.03885504975914955\n",
      "step 2100000, loss: 0.03883611783385277\n",
      "step 2200000, loss: 0.0388176366686821\n",
      "step 2300000, loss: 0.0387994684278965\n",
      "step 2400000, loss: 0.03878159448504448\n",
      "step 2500000, loss: 0.03876668959856033\n",
      "step 2600000, loss: 0.03875333070755005\n",
      "step 2700000, loss: 0.03874028101563454\n",
      "step 2800000, loss: 0.038727208971977234\n",
      "step 2900000, loss: 0.03871483355760574\n",
      "step 3000000, loss: 0.03870395943522453\n",
      "step 3100000, loss: 0.038693178445100784\n",
      "step 3200000, loss: 0.03868310526013374\n",
      "step 3300000, loss: 0.03867342695593834\n",
      "step 3400000, loss: 0.03866485506296158\n",
      "step 3500000, loss: 0.03865395858883858\n",
      "step 3600000, loss: 0.0386410653591156\n",
      "step 3700000, loss: 0.038628410547971725\n",
      "step 3800000, loss: 0.03861132636666298\n",
      "step 3900000, loss: 0.0385979562997818\n",
      "step 4000000, loss: 0.0385899618268013\n",
      "step 4100000, loss: 0.03858201950788498\n",
      "step 4200000, loss: 0.03857409954071045\n",
      "step 4300000, loss: 0.03856661170721054\n",
      "step 4400000, loss: 0.03855964168906212\n",
      "step 4500000, loss: 0.038552701473236084\n",
      "step 4600000, loss: 0.038545750081539154\n",
      "step 4700000, loss: 0.038538455963134766\n",
      "step 4800000, loss: 0.03853120654821396\n",
      "step 4900000, loss: 0.038523994386196136\n",
      "step 5000000, loss: 0.0385168194770813\n",
      "step 5100000, loss: 0.038509685546159744\n",
      "step 5200000, loss: 0.03850259631872177\n",
      "step 5300000, loss: 0.038495730608701706\n",
      "step 5400000, loss: 0.03848910331726074\n",
      "step 5500000, loss: 0.03848250210285187\n",
      "step 5600000, loss: 0.03847593441605568\n",
      "step 5700000, loss: 0.03846940025687218\n",
      "step 5800000, loss: 0.038462892174720764\n",
      "step 5900000, loss: 0.03845638781785965\n",
      "step 6000000, loss: 0.03844991326332092\n",
      "step 6100000, loss: 0.03844330459833145\n",
      "step 6200000, loss: 0.03843687102198601\n",
      "step 6300000, loss: 0.03843216225504875\n",
      "step 6400000, loss: 0.038427967578172684\n",
      "step 6500000, loss: 0.0384238138794899\n",
      "step 6600000, loss: 0.03841935098171234\n",
      "step 6700000, loss: 0.038414668291807175\n",
      "step 6800000, loss: 0.03840990737080574\n",
      "step 6900000, loss: 0.038405194878578186\n",
      "step 7000000, loss: 0.03840063884854317\n",
      "step 7100000, loss: 0.03839609771966934\n",
      "step 7200000, loss: 0.0383915901184082\n",
      "step 7300000, loss: 0.03838710859417915\n",
      "step 7400000, loss: 0.03838255628943443\n",
      "step 7500000, loss: 0.038377922028303146\n",
      "step 7600000, loss: 0.038373611867427826\n",
      "step 7700000, loss: 0.0383697971701622\n",
      "step 7800000, loss: 0.038366060703992844\n",
      "step 7900000, loss: 0.03836251050233841\n",
      "step 8000000, loss: 0.03835894539952278\n",
      "step 8100000, loss: 0.03835538774728775\n",
      "step 8200000, loss: 0.03835183009505272\n",
      "step 8300000, loss: 0.03834826871752739\n",
      "step 8400000, loss: 0.038344722241163254\n",
      "step 8500000, loss: 0.038341253995895386\n",
      "step 8600000, loss: 0.038337741047143936\n",
      "step 8700000, loss: 0.0383341945707798\n",
      "step 8800000, loss: 0.03833066672086716\n",
      "step 8900000, loss: 0.03832852840423584\n",
      "step 9000000, loss: 0.03832695633172989\n",
      "step 9100000, loss: 0.03832544386386871\n",
      "step 9200000, loss: 0.038323935121297836\n",
      "step 9300000, loss: 0.038322437554597855\n",
      "step 9400000, loss: 0.038320932537317276\n",
      "step 9500000, loss: 0.03831944614648819\n",
      "step 9600000, loss: 0.038317956030368805\n",
      "step 9700000, loss: 0.03831646591424942\n",
      "step 9800000, loss: 0.03831498697400093\n",
      "step 9900000, loss: 0.03831351548433304\n"
     ]
    }
   ],
   "source": [
    "theta = train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af6573e6-5d2e-45b0-9f06-ff12280649e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.94736844, dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [mu, sigma, theta]\n",
    "y_pred = predict(params, X_test)\n",
    "accuracy(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c524e7bb-04ed-4519-93d2-d4da300e8d60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114, 30)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "39a98d1b-2eaa-4185-afb0-5fd033e11992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "109/114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74438ff0-a34d-43cc-863e-d03e08cb5fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
