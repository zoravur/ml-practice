{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b5af73-c3ab-449c-a260-8cfacdd73812",
   "metadata": {},
   "source": [
    "sure. here's the clean mathematical breakdown, step by step:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Momentum**\n",
    "\n",
    "exponential moving average of gradient — smooths direction:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_t &= \\beta m_{t-1} + (1 - \\beta) g_t \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\eta \\cdot m_t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* $\\beta \\in [0,1)$: momentum coefficient (typically 0.9)\n",
    "* $\\eta$: learning rate\n",
    "* $g_t = \\nabla_\\theta L(\\theta_t)$: gradient at time $t$\n",
    "\n",
    "---\n",
    "\n",
    "### **2. RMSprop**\n",
    "\n",
    "scales update by EMA of squared gradient — adaptive step size:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v_t &= \\beta v_{t-1} + (1 - \\beta) g_t^2 \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\eta \\cdot \\frac{g_t}{\\sqrt{v_t} + \\epsilon}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* $\\epsilon$: small constant (e.g. $10^{-8}$) to avoid divide-by-zero\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Adam**\n",
    "\n",
    "momentum + RMSprop + **bias correction**:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m_t &= \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\quad &\\text{(1st moment)} \\\\\n",
    "v_t &= \\beta_2 v_{t-1} + (1 - \\beta_2) g_t^2 \\quad &\\text{(2nd moment)} \\\\\n",
    "\\hat{m}_t &= \\frac{m_t}{1 - \\beta_1^t} \\quad &\\text{(bias-corrected)} \\\\\n",
    "\\hat{v}_t &= \\frac{v_t}{1 - \\beta_2^t} \\\\\n",
    "\\theta_t &= \\theta_{t-1} - \\eta \\cdot \\frac{\\hat{m}_t}{\\sqrt{\\hat{v}_t} + \\epsilon}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "* typical values:\n",
    "  $\\beta_1 = 0.9,\\ \\beta_2 = 0.999,\\ \\epsilon = 10^{-8}$\n",
    "\n",
    "---\n",
    "\n",
    "each is a refinement on the last:\n",
    "\n",
    "* **momentum** smooths updates.\n",
    "* **RMSprop** adapts learning rate per parameter.\n",
    "* **Adam** does both and fixes startup bias.\n",
    "\n",
    "you can think of Adam as the fusion reactor built from the raw fuel of momentum and RMSprop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78edf6-3b1a-426b-bf9f-8ae7bc1cb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *gasp* Adam!\n",
    "def adam_update_single(params, m, v, t, g, lr=1e-3, b1=0.9, b2=0.999, eps=1e-8):\n",
    "    # g is gradient at timestep opt_state['t']\n",
    "    t = opt_state['t'] + 1\n",
    "    \n",
    "    m = b1*opt_state['m'] + (1 - b1)*g\n",
    "    v = b2*opt_state['v'] + (1 - b2)*jnp.square(g)\n",
    "\n",
    "    m /= 1 - b1**t\n",
    "    v /= 1 - b2**t\n",
    "    \n",
    "    params = opt_state['params'] - lr * (m / (jnp.sqrt(v) + eps))\n",
    "    \n",
    "    return {'params': params, 'm': m, 'v': v, 't': t}\n",
    "\n",
    "@jax.jit\n",
    "def adam_update(params, m, v, t, g, lr=1e-3, b1=0.9, b2=0.999, eps=1e-8):\n",
    "    opt_state = jax.tree.map(lambda params, m, v, t, g: adam_update_single(params, m, v, t, g, lr, b1, b2, eps), params, m, v, t, g)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6b0f3c-c120-4453-8981-e41757e3b188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam!\n",
    "@jax.jit\n",
    "def adam_update(opt_state, X, y, lr=1e-3, b1=0.9, b2=0.999, eps=1e-8):\n",
    "    grads = grad_loss(opt_state['params'], X, y)\n",
    "    t = opt_state['t'] + 1\n",
    "\n",
    "    m = jax.tree_util.tree_map(lambda m, g: b1 * m + (1 - b1) * g, opt_state['m'], grads)\n",
    "    v = jax.tree_util.tree_map(lambda v, g: b2 * v + (1 - b2) * (g * g), opt_state['v'], grads)\n",
    "\n",
    "    m_hat = jax.tree_util.tree_map(lambda m: m / (1 - b1**t), m)\n",
    "    v_hat = jax.tree_util.tree_map(lambda v: v / (1 - b2**t), v)\n",
    "\n",
    "    params = jax.tree_util.tree_map(\n",
    "        lambda p, m, v: p - lr * m / (jnp.sqrt(v) + eps),\n",
    "        opt_state['params'], m_hat, v_hat\n",
    "    )\n",
    "\n",
    "    return {'params': params, 'm': m, 'v': v, 't': t}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
